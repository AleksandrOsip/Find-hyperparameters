{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991c6215",
   "metadata": {},
   "source": [
    "Наша практика будет основана на соревновании [Kaggle: Predicting a Biological Response](https://www.kaggle.com/c/bioresponse) (Прогнозирование биологического ответа).\n",
    "\n",
    "Необходимо предсказать биологический ответ молекул (столбец 'Activity') по их химическому составу (столбцы D1-D1776).\n",
    "\n",
    "Данные представлены в формате CSV.  Каждая строка представляет молекулу. \n",
    "\n",
    "* Первый столбец Activity содержит экспериментальные данные, описывающие фактический биологический ответ [0, 1]; \n",
    "* Остальные столбцы D1-D1776 представляют собой молекулярные **дескрипторы** — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7eb147",
   "metadata": {},
   "source": [
    "Предварительная обработка не требуется, данные уже закодированы и нормализованы.\n",
    "\n",
    "В качестве метрики будем использовать **F1-score**.\n",
    "\n",
    "Необходимо обучить две модели: **логистическую регрессию и случайный лес**. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать **все четыре метода** (GridSearchCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций не должно превышать 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b2cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#импорт библиотек\n",
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные модели\n",
    "# from sklearn import tree #деревья решений\n",
    "from sklearn import ensemble #ансамбли\n",
    "from sklearn import metrics #метрики\n",
    "# from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #сплитование выборки\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df53fa",
   "metadata": {},
   "source": [
    "### Знакомство с данными и их исследование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb54ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\User\\SkillFactory\\data\\_train_sem09__1_.zip')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "429c08c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3751 entries, 0 to 3750\n",
      "Columns: 1777 entries, Activity to D1776\n",
      "dtypes: float64(942), int64(835)\n",
      "memory usage: 50.9 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3bfc3",
   "metadata": {},
   "source": [
    "Проверяем наличие пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7156da3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().unique() # Пропусков нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb08bd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.542255</td>\n",
       "      <td>0.076948</td>\n",
       "      <td>0.592436</td>\n",
       "      <td>0.068142</td>\n",
       "      <td>0.038990</td>\n",
       "      <td>0.212112</td>\n",
       "      <td>0.686653</td>\n",
       "      <td>0.274713</td>\n",
       "      <td>0.455133</td>\n",
       "      <td>0.749517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026926</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.015196</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.020261</td>\n",
       "      <td>0.011197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498278</td>\n",
       "      <td>0.079989</td>\n",
       "      <td>0.105860</td>\n",
       "      <td>0.078414</td>\n",
       "      <td>0.115885</td>\n",
       "      <td>0.102592</td>\n",
       "      <td>0.078702</td>\n",
       "      <td>0.090017</td>\n",
       "      <td>0.162731</td>\n",
       "      <td>0.071702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161889</td>\n",
       "      <td>0.120215</td>\n",
       "      <td>0.116938</td>\n",
       "      <td>0.146249</td>\n",
       "      <td>0.122348</td>\n",
       "      <td>0.128522</td>\n",
       "      <td>0.110074</td>\n",
       "      <td>0.107683</td>\n",
       "      <td>0.140911</td>\n",
       "      <td>0.105236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.137873</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.517811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138118</td>\n",
       "      <td>0.625627</td>\n",
       "      <td>0.207374</td>\n",
       "      <td>0.378062</td>\n",
       "      <td>0.707339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.585989</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190926</td>\n",
       "      <td>0.674037</td>\n",
       "      <td>0.277845</td>\n",
       "      <td>0.499942</td>\n",
       "      <td>0.738961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.668395</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261726</td>\n",
       "      <td>0.740663</td>\n",
       "      <td>0.335816</td>\n",
       "      <td>0.569962</td>\n",
       "      <td>0.788177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964381</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994735</td>\n",
       "      <td>0.790831</td>\n",
       "      <td>0.989870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Activity           D1           D2           D3           D4  \\\n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
       "mean      0.542255     0.076948     0.592436     0.068142     0.038990   \n",
       "std       0.498278     0.079989     0.105860     0.078414     0.115885   \n",
       "min       0.000000     0.000000     0.282128     0.000000     0.000000   \n",
       "25%       0.000000     0.033300     0.517811     0.000000     0.000000   \n",
       "50%       1.000000     0.066700     0.585989     0.050000     0.000000   \n",
       "75%       1.000000     0.100000     0.668395     0.100000     0.000000   \n",
       "max       1.000000     1.000000     0.964381     0.950000     1.000000   \n",
       "\n",
       "                D5           D6           D7           D8           D9  ...  \\\n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  ...   \n",
       "mean      0.212112     0.686653     0.274713     0.455133     0.749517  ...   \n",
       "std       0.102592     0.078702     0.090017     0.162731     0.071702  ...   \n",
       "min       0.002630     0.137873     0.006130     0.000000     0.275590  ...   \n",
       "25%       0.138118     0.625627     0.207374     0.378062     0.707339  ...   \n",
       "50%       0.190926     0.674037     0.277845     0.499942     0.738961  ...   \n",
       "75%       0.261726     0.740663     0.335816     0.569962     0.788177  ...   \n",
       "max       1.000000     0.994735     0.790831     0.989870     1.000000  ...   \n",
       "\n",
       "             D1767        D1768        D1769        D1770        D1771  \\\n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
       "mean      0.026926     0.014663     0.013863     0.021861     0.015196   \n",
       "std       0.161889     0.120215     0.116938     0.146249     0.122348   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             D1772        D1773        D1774        D1775        D1776  \n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  \n",
       "mean      0.016796     0.012263     0.011730     0.020261     0.011197  \n",
       "std       0.128522     0.110074     0.107683     0.140911     0.105236  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 1777 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c135a",
   "metadata": {},
   "source": [
    "Смотрим на сбалансированность классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2d4209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Activity', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=data, x='Activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b6055",
   "metadata": {},
   "source": [
    "Создаем матрицу наблюдений $X$ и вектор ответов $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108a32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Activity'], axis=1)\n",
    "y = data['Activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6a6e9",
   "metadata": {},
   "source": [
    "Разделяем выборку на тренировочную и тестовую в соотношении 80/20. Для сохранения соотношений целевого признака используем параметр stratify (стратифицированное разбиение)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ea3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 1, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f71e74f",
   "metadata": {},
   "source": [
    "### Оптимизация гиперпараметров модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b60637",
   "metadata": {},
   "source": [
    "#### **Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b1bcfe",
   "metadata": {},
   "source": [
    "Зафиксируем только метрики, которые были получены без дополнительной настройки, т.е со значениями гиперпараметров, установленных по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ef511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовом наборе: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса логистическая регрессия\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "#Обучаем модель, минимизируя logloss\n",
    "log_reg.fit(X_train, y_train)\n",
    "# print(\"accuracy на тестовом наборе: {:.2f}\".format(log_reg.score(X_test_scaled, y_test)))\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50acabb3",
   "metadata": {},
   "source": [
    "**Случайный лес**\n",
    "\n",
    "Проделаем аналогичное для RandomForestClassifier(). Сначала посчитаем модель с параметрами по умолчанию и оценим метрику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e642bb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовом наборе: 0.81\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса случайный лес\n",
    "rf = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Обучаем модель\n",
    "rf.fit(X_train, y_train)\n",
    "#Выводим значения метрики \n",
    "y_train_pred = rf.predict(X_train)\n",
    "# print('Train: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01d5ff",
   "metadata": {},
   "source": [
    "### <center> **GridSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b80bb",
   "metadata": {},
   "source": [
    "**Для логистической регрессии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfab0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.89 s\n",
      "Wall time: 44.5 s\n",
      "f1_score на тестовом наборе: 0.78\n",
      "Наилучшие значения гиперпараметров: {'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'penalty': ['l2', 'none'], #тип регурялизации\n",
    "              'solver': ['lbfgs', 'saga'], #алгоритм оптимизации\n",
    "              }\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        max_iter=50 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search.fit(X_train, y_train) \n",
    "# print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5a38a",
   "metadata": {},
   "source": [
    "Значение метрики не изменилось, но это значит лишь, что мы не нашли комбинацию внешних параметров лучше, чем заданы по умолчанию. Это не удивительно и достаточно часто исходные гиперпараметры дают неплохой результат, но это не повод останавливаться."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0637d06",
   "metadata": {},
   "source": [
    "**Попробуем расширить сетку гиперпараметров.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "045ee21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.1 s\n",
      "Wall time: 5min 56s\n",
      "f1_score на тестовом наборе: 0.79\n",
      "Наилучшие значения гиперпараметров: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "              {'penalty': ['l2', 'none'], # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'],\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "]\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        max_iter=50 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_1.fit(X_train, y_train)\n",
    "y_test_pred = grid_search_1.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_1.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa8eb29",
   "metadata": {},
   "source": [
    "**Метрику удалось улучшить, а время потратили много, в 8 раз больше!**\n",
    "\n",
    "Поиск по сетке не гарантирует, что мы найдем наилучшую комбинацию гиперпараметров, а все потому что сетка значений конечна и фактическое наилучшее значение может отсутствовать или оказаться между значений, заданными нами.\n",
    "\n",
    "Ознакомиться с итоговой полученной моделью можно с помощью best_estimator_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff911c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая модель:\n",
      "LogisticRegression(max_iter=50, random_state=42, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшая модель:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c6e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая модель:\n",
      "LogisticRegression(C=0.1, max_iter=50, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшая модель:\\n{}\".format(grid_search_1.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3b9e1",
   "metadata": {},
   "source": [
    "**Для случайного леса**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce79875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.56 s\n",
      "Wall time: 1min 44s\n",
      "f1_score на тестовом наборе: 0.82\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
    "              'min_samples_leaf': [5],\n",
    "              'max_depth': list(np.linspace(20, 40, 5, dtype=int))\n",
    "              }\n",
    "            \n",
    "grid_search_forest = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_forest.fit(X_train, y_train) \n",
    "y_train_pred = grid_search_forest.predict(X_train)\n",
    "# print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "# print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_forest.score(X_test, y_test)))\n",
    "y_test_pred = grid_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ccb678",
   "metadata": {},
   "source": [
    "### <center> **RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff809c",
   "metadata": {},
   "source": [
    "**Для логистической регресии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a79b41aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.22 s\n",
      "Wall time: 47.9 s\n",
      "f1_score на тестовом наборе: 0.79\n",
      "Наилучшие значения гиперпараметров: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#np.linspace(start(от), stop(до), num=50(количество),dtype- тип данных)\n",
    "param_grid = {'penalty': ['l2', 'none'] ,\n",
    "              'solver': ['lbfgs', 'sag'],\n",
    "               'C': list(np.linspace(0.01, 1, 10, dtype=float))\n",
    "             }\n",
    "            \n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        max_iter=50 #количество итераций на сходимость\n",
    "    ),\n",
    "    param_distributions=param_grid,\n",
    "    cv=5, \n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search.fit(X_train, y_train) \n",
    "# print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search.score(X_test, y_test)))\n",
    "y_test_pred = random_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a583f96",
   "metadata": {},
   "source": [
    "**Для случайного леса**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a5fb1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.53 s\n",
      "Wall time: 1min\n",
      "f1_score на тестовом наборе: 0.83\n",
      "Наилучшие значения гиперпараметров: {'n_estimators': 140, 'min_samples_leaf': 5, 'max_depth': 22}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
    "              'min_samples_leaf': [5],\n",
    "              'max_depth': list(np.linspace(20, 40, 10, dtype=int))\n",
    "              }\n",
    "            \n",
    "random_search_forest = RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_distributions=param_grid, \n",
    "    cv=5,\n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search_forest.fit(X_train, y_train) \n",
    "y_train_pred = random_search_forest.predict(X_train)\n",
    "# print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "# print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search_forest.score(X_test, y_test)))\n",
    "y_test_pred = random_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a636130c",
   "metadata": {},
   "source": [
    "### <center> Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8b25c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия Hyperopt : 0.2.7\n"
     ]
    }
   ],
   "source": [
    "#делаем импорт и выведем версию библиотеки\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "# fmin - основная функция, она будет минимизировать наш функционал\n",
    "# tpe - алгоритм оптимизации\n",
    "# hp - включает набор методов для объявления пространства поиска гиперпараметров\n",
    "# trails - используется для логирования результатов\n",
    "\n",
    "print(\"Версия Hyperopt : {}\".format(hyperopt.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150b713",
   "metadata": {},
   "source": [
    "**Для случайного леса**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7076744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e8d9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # обучать модель можно также с помощью кросс-валидации\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91baa3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████| 20/20 [01:21<00:00,  4.05s/trial, best loss: -0.988653787181846]\n",
      "Наилучшие значения гиперпараметров {'max_depth': 18.0, 'min_samples_leaf': 2.0, 'n_estimators': 103.0}\n",
      "CPU times: total: 1min 20s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_rf, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0690bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовом наборе: 0.82\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "# print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "# print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9943f48e",
   "metadata": {},
   "source": [
    "**Для логистической регрессии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5613e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "# Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "space={'penalty': ['l2', 'none'] ,\n",
    "    'solver': ['lbfgs', 'sag'],\n",
    "    'C': list(np.linspace(0.01, 1, 10, dtype=float))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "433422bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_lr(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = space\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(\n",
    "       **params,\n",
    "        random_state=random_state,\n",
    "        max_iter=50\n",
    "    )\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # обучать модель можно также с помощью кросс-валидации\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea66815f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                   | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got ['lbfgs', 'sag'].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                   | 0/20 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got ['lbfgs', 'sag'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mE:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mE:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mE:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mE:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mE:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mE:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mhyperopt_lr\u001b[1;34m(params, cv, X, y, random_state)\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLogisticRegression(\n\u001b[0;32m      9\u001b[0m    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m     10\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[0;32m     11\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# обучаем модель\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mf1_score(y, model\u001b[38;5;241m.\u001b[39mpredict(X))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# обучать модель можно также с помощью кросс-валидации\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# применим  cross validation с тем же количеством фолдов\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# метрику необходимо минимизировать, поэтому ставим знак минус\u001b[39;00m\n",
      "File \u001b[1;32mE:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1461\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1433\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;124;03m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1461\u001b[0m     solver \u001b[38;5;241m=\u001b[39m \u001b[43m_check_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC, numbers\u001b[38;5;241m.\u001b[39mNumber) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1464\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPenalty term must be positive; got (C=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC)\n",
      "File \u001b[1;32mE:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:434\u001b[0m, in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    432\u001b[0m all_solvers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_solvers:\n\u001b[1;32m--> 434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression supports only solvers in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;241m%\u001b[39m (all_solvers, solver)\n\u001b[0;32m    437\u001b[0m     )\n\u001b[0;32m    439\u001b[0m all_penalties \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m penalty \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_penalties:\n",
      "\u001b[1;31mValueError\u001b[0m: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got ['lbfgs', 'sag']."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_lr, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state) # фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4dca8",
   "metadata": {},
   "source": [
    "## <center> Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b54b0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf7a438",
   "metadata": {},
   "source": [
    "**Для логистической регрессии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92bf7deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_lr(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    penalty = ['12', 'none']\n",
    "    solver = ['lbfgs', 'sag']\n",
    "    \n",
    "    # создаем модель\n",
    "    model = linear_model.LogisticRegression(penalty=penalty,\n",
    "                                            solver=solver,\n",
    "                                            random_state=random_state)\n",
    "    # обучаем модель\n",
    "    model.fit(X_train, y_train)\n",
    "    score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df3dd476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-11 21:17:17,671]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
      "\u001b[33m[W 2022-06-11 21:17:17,675]\u001b[0m Trial 0 failed because of the following error: ValueError(\"Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got ['lbfgs', 'sag'].\")\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6608\\3669723828.py\", line 11, in optuna_lr\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 434, in _check_solver\n",
      "    raise ValueError(\"Logistic Regression supports only solvers in %s, got\"\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got ['lbfgs', 'sag'].\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got ['lbfgs', 'sag'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mD:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\optuna\\study\\study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis feature will be removed in v4.0.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 400\u001b[0m \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[1;32mD:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\optuna\\study\\_optimize.py:264\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch):\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\n",
      "File \u001b[1;32mD:\\ProgramData7\\Anaconda3\\envs\\my-env\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    210\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36moptuna_lr\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLogisticRegression(penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[0;32m      8\u001b[0m                                         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[0;32m      9\u001b[0m                                         random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# обучаем модель\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mf1_score(y_train, model\u001b[38;5;241m.\u001b[39mpredict(X_train))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:1306\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1304\u001b[0m \u001b[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1306\u001b[0m     solver \u001b[38;5;241m=\u001b[39m \u001b[43m_check_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC, numbers\u001b[38;5;241m.\u001b[39mNumber) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPenalty term must be positive; got (C=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1310\u001b[0m                          \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:434\u001b[0m, in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    432\u001b[0m all_solvers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_solvers:\n\u001b[1;32m--> 434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression supports only solvers in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (all_solvers, solver))\n\u001b[0;32m    437\u001b[0m all_penalties \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m penalty \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_penalties:\n",
      "\u001b[1;31mValueError\u001b[0m: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got ['lbfgs', 'sag']."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_lr, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d076b4d",
   "metadata": {},
   "source": [
    "**Для случайного леса**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20ebb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
    "\n",
    "    # создаем модель\n",
    "    model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                            max_depth=max_depth,\n",
    "                                            min_samples_leaf=min_samples_leaf,\n",
    "                                            random_state=random_state)\n",
    "    # обучаем модель\n",
    "    model.fit(X_train, y_train)\n",
    "    score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcc5bbef",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-11 20:32:33,968]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:32:37,017]\u001b[0m Trial 0 finished with value: 0.9350411710887466 and parameters: {'n_estimators': 130, 'max_depth': 13, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9350411710887466.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:32:40,469]\u001b[0m Trial 1 finished with value: 0.9440538061754814 and parameters: {'n_estimators': 144, 'max_depth': 15, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.9440538061754814.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:32:44,741]\u001b[0m Trial 2 finished with value: 0.9279609279609279 and parameters: {'n_estimators': 193, 'max_depth': 28, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.9440538061754814.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:32:48,633]\u001b[0m Trial 3 finished with value: 0.9216166564605022 and parameters: {'n_estimators': 178, 'max_depth': 15, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.9440538061754814.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:32:52,302]\u001b[0m Trial 4 finished with value: 0.9758335882532885 and parameters: {'n_estimators': 141, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9758335882532885.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:32:55,778]\u001b[0m Trial 5 finished with value: 0.9174311926605505 and parameters: {'n_estimators': 159, 'max_depth': 25, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.9758335882532885.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:32:59,186]\u001b[0m Trial 6 finished with value: 0.9086465016804156 and parameters: {'n_estimators': 161, 'max_depth': 28, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.9758335882532885.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:02,991]\u001b[0m Trial 7 finished with value: 0.989874194538202 and parameters: {'n_estimators': 140, 'max_depth': 19, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.989874194538202.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:05,920]\u001b[0m Trial 8 finished with value: 0.9058679706601467 and parameters: {'n_estimators': 138, 'max_depth': 15, 'min_samples_leaf': 9}. Best is trial 7 with value: 0.989874194538202.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:09,956]\u001b[0m Trial 9 finished with value: 0.906087488528602 and parameters: {'n_estimators': 188, 'max_depth': 19, 'min_samples_leaf': 9}. Best is trial 7 with value: 0.989874194538202.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:12,403]\u001b[0m Trial 10 finished with value: 0.9335782063054789 and parameters: {'n_estimators': 104, 'max_depth': 10, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.989874194538202.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:15,731]\u001b[0m Trial 11 finished with value: 0.9917203311867526 and parameters: {'n_estimators': 118, 'max_depth': 21, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9917203311867526.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:18,855]\u001b[0m Trial 12 finished with value: 0.9791794243723209 and parameters: {'n_estimators': 117, 'max_depth': 20, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.9917203311867526.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:22,237]\u001b[0m Trial 13 finished with value: 0.9920294297976702 and parameters: {'n_estimators': 120, 'max_depth': 23, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:24,835]\u001b[0m Trial 14 finished with value: 0.9600000000000001 and parameters: {'n_estimators': 102, 'max_depth': 23, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:27,904]\u001b[0m Trial 15 finished with value: 0.9596823457544289 and parameters: {'n_estimators': 122, 'max_depth': 23, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:31,181]\u001b[0m Trial 16 finished with value: 0.9911124731841863 and parameters: {'n_estimators': 116, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:34,190]\u001b[0m Trial 17 finished with value: 0.977328431372549 and parameters: {'n_estimators': 111, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:37,253]\u001b[0m Trial 18 finished with value: 0.9443084455324358 and parameters: {'n_estimators': 127, 'max_depth': 17, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:33:41,149]\u001b[0m Trial 19 finished with value: 0.9571341090018372 and parameters: {'n_estimators': 156, 'max_depth': 22, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 6s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cd63498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 120, 'max_depth': 23, 'min_samples_leaf': 2}\n",
      "f1_score на обучающем наборе: 0.99\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81b83b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.80\n",
      "f1_score на тестовом наборе: 0.82\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d547bba",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-11 20:37:40,615]\u001b[0m Trial 20 finished with value: 0.9917203311867526 and parameters: {'n_estimators': 130, 'max_depth': 26, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:37:44,250]\u001b[0m Trial 21 finished with value: 0.9914163090128756 and parameters: {'n_estimators': 129, 'max_depth': 26, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:37:47,199]\u001b[0m Trial 22 finished with value: 0.9773561811505507 and parameters: {'n_estimators': 111, 'max_depth': 21, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:37:50,854]\u001b[0m Trial 23 finished with value: 0.9914163090128756 and parameters: {'n_estimators': 131, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:37:54,050]\u001b[0m Trial 24 finished with value: 0.9755052051439068 and parameters: {'n_estimators': 121, 'max_depth': 24, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:37:57,543]\u001b[0m Trial 25 finished with value: 0.9351285189718482 and parameters: {'n_estimators': 150, 'max_depth': 21, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:38:00,256]\u001b[0m Trial 26 finished with value: 0.9593147751605995 and parameters: {'n_estimators': 107, 'max_depth': 30, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:38:03,702]\u001b[0m Trial 27 finished with value: 0.9914163090128756 and parameters: {'n_estimators': 124, 'max_depth': 26, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:38:06,533]\u001b[0m Trial 28 finished with value: 0.9006420055029044 and parameters: {'n_estimators': 135, 'max_depth': 17, 'min_samples_leaf': 10}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n",
      "\u001b[32m[I 2022-06-11 20:38:10,622]\u001b[0m Trial 29 finished with value: 0.9460530326120087 and parameters: {'n_estimators': 167, 'max_depth': 19, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.9920294297976702.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 33.4 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# можем прододжить подбор, указав n_trials(любое число, которое добавится к предыдущим итерациям) \n",
    "study.optimize(optuna_rf, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d146219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 120, 'max_depth': 23, 'min_samples_leaf': 2}\n",
      "f1_score на обучающем наборе: 0.99\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13976b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.80\n",
      "f1_score на тестовом наборе: 0.82\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa90fc",
   "metadata": {},
   "source": [
    "Добавление 10 итераций никакого улучшения не дало."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
